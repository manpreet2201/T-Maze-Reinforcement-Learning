{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of assignment8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7FT0RDpVm8_"
      },
      "source": [
        "Part a) Modifying the program RLmlp,10 states are represented in the linear maze within a tabular representation of the states. The rewards at state 0  set at 1, and the rewards at state 9  set to two. The reward on all other states is 0. The discount factor  set to gamma=0.8. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBj4RcUixVOI"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers, optimizers\n",
        "\n",
        "def tau(s,a):\n",
        "    if (s[0] and s[9]) == 0 : s=np.roll(s,a)\n",
        "    return s\n",
        "\n",
        "def rho(s):\n",
        "    return ((s[0]==1)+2*(s[9]==1))    \n",
        "\n",
        "def terminal_state(s):\n",
        "    return (s[0]==1 or s[9]==1)    \n",
        "\n",
        "gamma=0.8\n",
        "invT = 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p7fNZJAxr6P"
      },
      "source": [
        "# the network\n",
        "inputs = layers.Input(shape=(10,))\n",
        "h = layers.Dense(20, activation='relu')(inputs)\n",
        "outputs = layers.Dense(2, activation='linear')(h)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "RMSprop = optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='mse', optimizer=RMSprop)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLEgFm7p2fgf"
      },
      "source": [
        "for trial in range(400):\n",
        "    s= np.array([0,0,0,0,1,0,0,0,0,0])\n",
        "    for t in range(0,10):\n",
        "        if terminal_state(s): break\n",
        "        if trial > 30 and invT > 0.1: invT -= 0.001\n",
        "        prediction=model.predict(s.reshape(1,10), steps=1, verbose=0)\n",
        "        aidx=np.argmax(prediction)\n",
        "        if np.random.rand() < invT : aidx=1-aidx\n",
        "        a=2*aidx-1\n",
        "        next_s = tau(s,a)\n",
        "        if terminal_state(next_s): \n",
        "            y = rho(next_s)\n",
        "        else:\n",
        "            y = gamma*np.max(model.predict(next_s.reshape(1,10), steps=1, verbose=0))\n",
        "        prediction[0,aidx]=y\n",
        "        model.fit(s.reshape(1,10), prediction, epochs=1, verbose=0)\n",
        "        s = np.copy(next_s)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcsLq15hWsvj"
      },
      "source": [
        "Computed Q values and policies from trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs0vIU9T2iHq",
        "outputId": "f5ec2da0-c21f-45ca-bb5b-47d2247219ac"
      },
      "source": [
        "policy = np.zeros(10)\n",
        "Q=[]\n",
        "s = np.array([1,0,0,0,0,0,0,0,0,0])\n",
        "\n",
        "for i in range(0,10):\n",
        "    Qs=model.predict(s.reshape(1,10), steps=1)\n",
        "    Q.append(Qs)\n",
        "    aidx=np.argmax(Qs)\n",
        "    policy[i]=2*aidx-1\n",
        "    s = np.roll(s,1)\n",
        "print('Qvalues:', np.transpose(Q))\n",
        "print('policy:',np.transpose(policy))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Qvalues: [[[0.5527975  0.85979396 0.6920488  0.6576191  0.46879047 0.6191393\n",
            "   0.7462076  0.98538595 1.271344   0.58717245]]\n",
            "\n",
            " [[0.8877659  0.62498385 0.49571478 0.6049864  0.78184664 1.0031447\n",
            "   1.2045466  1.5537133  1.9262716  0.63368785]]]\n",
            "policy: [ 1. -1. -1. -1.  1.  1.  1.  1.  1.  1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpMmYfJ2Wvop"
      },
      "source": [
        "Part b) Program where the state input is given with a simple number representing the state. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij3aXAPP399Z"
      },
      "source": [
        "\n",
        "def tau(s,a):\n",
        "    if (s != 0 and s != 9) : s = s+a\n",
        "    return s\n",
        "\n",
        "def rho(s):\n",
        "    return ((s == 0)+2*(s == 9))    \n",
        "\n",
        "def terminal_state(s):\n",
        "    return (s==0 or s==9)    \n",
        "\n",
        "gamma=0.8\n",
        "invT = 1"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYYXR-FCtqPw"
      },
      "source": [
        "# the network\n",
        "inputs = layers.Input(shape=(1,))\n",
        "h = layers.Dense(10, activation='relu')(inputs)\n",
        "outputs = layers.Dense(2, activation='linear')(h)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "RMSprop = optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='mse', optimizer=RMSprop)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_JOujUVua0r"
      },
      "source": [
        "for trial in range(400):\n",
        "    input = 4\n",
        "    s= np.array([input])\n",
        "    for t in range(0,10):\n",
        "        if terminal_state(s): break\n",
        "        if trial > 10 and invT > 0.1: invT -= 0.001\n",
        "        prediction=model.predict(s.reshape(1,1), steps=1, verbose=0)\n",
        "        aidx=np.argmax(prediction)\n",
        "        if np.random.rand() < invT : aidx=1-aidx\n",
        "        a=2*aidx-1\n",
        "        next_s = tau(s,a)\n",
        "        if terminal_state(next_s): \n",
        "            y = rho(next_s)\n",
        "        else:\n",
        "            y = gamma*np.max(model.predict(next_s.reshape(1,1), steps=1, verbose=0))\n",
        "        prediction[0,aidx]=y\n",
        "        model.fit(s.reshape(1,1), prediction, epochs=1, verbose=0)\n",
        "        s = np.copy(next_s)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0Mp80qOW_vv"
      },
      "source": [
        "Computed Q values and policies from trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ7krXIEuvVa",
        "outputId": "2791da4a-5bdc-4fdd-bcff-252110907586"
      },
      "source": [
        "policy = np.zeros(10)\n",
        "Q=[]\n",
        "s = np.array([0])\n",
        "for i in range(0,10):\n",
        "    Qs=model.predict(s.reshape(1,1), steps=1)\n",
        "    Q.append(Qs)\n",
        "    aidx=np.argmax(Qs)\n",
        "    policy[i]=2*aidx-1\n",
        "    s = s+1\n",
        "print('Q value:',np.transpose(Q))\n",
        "print('policy:',np.transpose(policy))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q value: [[[ 1.1015149   1.001903    0.8005586   0.638415    0.5216539\n",
            "    0.4048928   0.2881317   0.17351794  0.06296086 -0.04759622]]\n",
            "\n",
            " [[ 0.8446406   0.61589694  0.40262255  0.30086264  0.3253796\n",
            "    0.34989658  0.37441355  0.39706606  0.41619626  0.43532646]]]\n",
            "policy: [-1. -1. -1. -1. -1. -1.  1.  1.  1.  1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixNuwK9sXCG_"
      },
      "source": [
        "Part c) Program where a trained network is used to recognise a hand-written number from MNIST that then becomes the input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "mKrKt_RKxV4H",
        "outputId": "3952260b-2f4a-430c-99c8-a93b0483177f"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers, optimizers, datasets, utils, losses\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "print(np.shape(x_train))\n",
        "plt.matshow(255-x_train[5,:,:], cmap='gray')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f56fa84d198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVX8TnJ4xuU-",
        "outputId": "2f58ca20-07aa-463d-ee1a-fe9f844bbc37"
      },
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1)/255\n",
        "x_train = x_train[:1024,:,:,:]\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)/255\n",
        "y_train = utils.to_categorical(y_train[:1024], 10)\n",
        "y_test = utils.to_categorical(y_test, 10)\n",
        "\n",
        "inputs = layers.Input(shape=(28, 28, 1,))\n",
        "x=layers.Conv2D(32, kernel_size=(3, 3),activation='relu')(inputs)\n",
        "x=layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x=layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x=layers.Dropout(0.25)(x)\n",
        "x=layers.Flatten()(x)\n",
        "x=layers.Dense(128, activation='relu')(x)\n",
        "x=layers.Dropout(0.5)(x)\n",
        "outputs=layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=losses.categorical_crossentropy,\n",
        "              optimizer=optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 7s 923ms/step - loss: 2.2991 - accuracy: 0.1426 - val_loss: 2.3001 - val_accuracy: 0.1214\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 7s 912ms/step - loss: 2.2991 - accuracy: 0.1152 - val_loss: 2.2995 - val_accuracy: 0.1221\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 7s 912ms/step - loss: 2.3002 - accuracy: 0.1426 - val_loss: 2.2989 - val_accuracy: 0.1229\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 2.2987 - accuracy: 0.1299 - val_loss: 2.2984 - val_accuracy: 0.1238\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 2.2985 - accuracy: 0.1338 - val_loss: 2.2978 - val_accuracy: 0.1249\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 2.2965 - accuracy: 0.1426 - val_loss: 2.2972 - val_accuracy: 0.1260\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 7s 911ms/step - loss: 2.2920 - accuracy: 0.1357 - val_loss: 2.2966 - val_accuracy: 0.1271\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 7s 908ms/step - loss: 2.2936 - accuracy: 0.1406 - val_loss: 2.2961 - val_accuracy: 0.1282\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 7s 920ms/step - loss: 2.2942 - accuracy: 0.1406 - val_loss: 2.2955 - val_accuracy: 0.1302\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 7s 916ms/step - loss: 2.2947 - accuracy: 0.1426 - val_loss: 2.2949 - val_accuracy: 0.1315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56facd5f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ptXjBbxwT1"
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdjaDFBTx_x7",
        "outputId": "54be8fe7-3f1c-4b0f-c4ac-732e6e48d86b"
      },
      "source": [
        "y_pred[1]\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1010065 , 0.10406297, 0.10054718, 0.09768872, 0.09274782,\n",
              "       0.09882107, 0.10310592, 0.09867769, 0.10133501, 0.10200706],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ9E8L0oUl-1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers, optimizers\n",
        "\n",
        "def tau(s,a):\n",
        "    if (s[0] and s[9]) == 0 : s=np.roll(s,a)\n",
        "    return s\n",
        "\n",
        "def rho(s):\n",
        "    return ((s[0]==1)+2*(s[9]==1))    \n",
        "\n",
        "def terminal_state(s):\n",
        "    return (s[0]==1 or s[9]==1)    \n",
        "\n",
        "gamma=0.8\n",
        "invT = 1"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKuk_bj7Useb"
      },
      "source": [
        "# the network\n",
        "inputs = layers.Input(shape=(10,))\n",
        "h = layers.Dense(20, activation='relu')(inputs)\n",
        "outputs = layers.Dense(2, activation='linear')(h)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "RMSprop = optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='mse', optimizer=RMSprop)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCuUl1ylUvUU"
      },
      "source": [
        "for trial in range(400):\n",
        "    s= y_pred[1]\n",
        "    for t in range(0,10):\n",
        "        if terminal_state(s): break\n",
        "        if trial > 30 and invT > 0.1: invT -= 0.001\n",
        "        prediction=model.predict(s.reshape(1,10), steps=1, verbose=0)\n",
        "        aidx=np.argmax(prediction)\n",
        "        if np.random.rand() < invT : aidx=1-aidx\n",
        "        a=2*aidx-1\n",
        "        next_s = tau(s,a)\n",
        "        if terminal_state(next_s): \n",
        "            y = rho(next_s)\n",
        "        else:\n",
        "            y = gamma*np.max(model.predict(next_s.reshape(1,10), steps=1, verbose=0))\n",
        "        prediction[0,aidx]=y\n",
        "        model.fit(s.reshape(1,10), prediction, epochs=1, verbose=0)\n",
        "        s = np.copy(next_s)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKR7BQJKXRco"
      },
      "source": [
        "Computed Q values and policies from trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7k_syLFU2dB",
        "outputId": "b6bce4ea-4128-477f-adc9-14228a0d0611"
      },
      "source": [
        "policy = np.zeros(10)\n",
        "Q=[]\n",
        "s = np.array([1,0,0,0,0,0,0,0,0,0])\n",
        "\n",
        "for i in range(0,10):\n",
        "    Qs=model.predict(s.reshape(1,10), steps=1)\n",
        "    Q.append(Qs)\n",
        "    aidx=np.argmax(Qs)\n",
        "    policy[i]=2*aidx-1\n",
        "    s = np.roll(s,1)\n",
        "print('Qvalues::',np.transpose(Q))\n",
        "print('policy:',np.transpose(policy))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Qvalues:: [[[ 0.11960339 -0.03430711  0.17766713 -0.24672556  0.00318126\n",
            "    0.07185458 -0.01885923 -0.11575116 -0.25628853  0.0263079 ]]\n",
            "\n",
            " [[ 0.32696596  0.01218712  0.2522636   0.22359307  0.2993686\n",
            "    0.21260919  0.3414943   0.19178493  0.32430103  0.02827294]]]\n",
            "policy: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}